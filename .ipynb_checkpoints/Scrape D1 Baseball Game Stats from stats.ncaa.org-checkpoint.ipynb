{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1612e912-3ba2-4da2-b442-9f6cbf39f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL IMPORTS AND FUNCTIONS\n",
    "from bs4 import BeautifulSoup\n",
    "from pyvirtualdisplay import Display\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from requests import Session\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#Open webpage and locate home and away tables to scrape boxstats\n",
    "def get_stats(url):\n",
    "    with Session() as s:\n",
    "        r = s.get('https://stats.ncaa.org'+url, headers=_HEADERS)\n",
    "    if r.status_code == 403:\n",
    "        print('An error occurred with the GET Request')\n",
    "        print('403 Error: NCAA blocked request')\n",
    "    soup = BeautifulSoup(r.text, features='lxml')\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    away_table = tables[5]\n",
    "    home_table = tables[6]\n",
    "\n",
    "    away_df = scrape_box_stats(away_table)\n",
    "    home_df = scrape_box_stats(home_table)\n",
    "\n",
    "    return away_df, home_df\n",
    "\n",
    "def scrape_box_stats(table):\n",
    "    headers = [header.text for header in table.find('tr', {'class': 'grey_heading'}).find_all('th')]        \n",
    "    data = []\n",
    "    for row in table.find_all('tr', {'class': 'smtext'}):\n",
    "        data.append([cell.text.strip().split('/')[0] for cell in row.find_all('td')])  # Split at '/' for dirty data and take the first part\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df = df.replace('', 0)\n",
    "    return df\n",
    "\n",
    "def get_team_names(table_html):\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(table_html, 'html.parser')\n",
    "\n",
    "    # Find the table rows\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Get the team names and remove the record in parentheses\n",
    "    away_team_name = rows[1].find('a').text.split(' (')[0].strip()\n",
    "    home_team_name = rows[2].find('a').text.split(' (')[0].strip()\n",
    "\n",
    "    return {\"Away Team\": away_team_name, \"Home Team\": home_team_name}\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_game_info(table_html):\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(table_html, 'html.parser')\n",
    "\n",
    "    # Find the table rows\n",
    "    rows = soup.find_all('tr')\n",
    "    # Get the game date, location, and attendance (if the data is available)\n",
    "    if len(rows)>=3:     \n",
    "        game_date = rows[0].find_all('td')[1].text.strip()\n",
    "        location = rows[1].find_all('td')[1].text.strip()\n",
    "        attendance = rows[2].find_all('td')[1].text.strip()\n",
    "    elif len(rows) == 2:\n",
    "        # Case: len(rows) = 2\n",
    "        game_date = rows[0].find_all('td')[1].text.strip()\n",
    "        location = rows[1].find_all('td')[1].text.strip()\n",
    "        attendance = None\n",
    "    elif len(rows) == 1:\n",
    "        # Case: len(rows) = 1\n",
    "        game_date = rows[0].find_all('td')[1].text.strip()\n",
    "        location = None\n",
    "        attendance = None\n",
    "    else:\n",
    "        # Case: len(rows) = 0\n",
    "        game_date, location, attendance = None, None, None\n",
    "\n",
    "    return {\"Game Date\": game_date, \"Location\": location, \"Attendance\": attendance}\n",
    "\n",
    "def get_box_score_links(html):\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Find all the 'a' tags\n",
    "    a_tags = soup.find_all('a')\n",
    "    # Get the links that contain \"box_score\"\n",
    "    links = [a['href'] for a in a_tags if \"box_score\" in a['href']]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5df902b-dcf9-4941-bd1a-39cbc4d04e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting stats from: https://stats.ncaa.org/contests/4493127/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/5253242/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/4530235/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/4530296/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/4530297/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/4530236/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/4529412/box_score\n",
      "Getting stats from: https://stats.ncaa.org/contests/4529875/box_score\n",
      "Finished scraping data from 8 games on 2024-03-11 00:00:00\n",
      "Time taken: 23.530757904052734 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# GET request options\n",
    "_HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# Define variables for ingestion script\n",
    "sport_code = \"MBA\"\n",
    "academic_year = \"2024\"\n",
    "division = \"1\"\n",
    "start_date_str = \"02/16/2024\"\n",
    "end_date_str = \"03/12/2024\"\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, \"%m/%d/%Y\")\n",
    "end_date = datetime.strptime(end_date_str, \"%m/%d/%Y\")\n",
    "date_range = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Create empty dataframes for final stats\n",
    "final_batting_df = pd.DataFrame()\n",
    "final_pitching_df = pd.DataFrame()\n",
    "final_fielding_df = pd.DataFrame()\n",
    "final_games_per_day = pd.DataFrame()\n",
    "\n",
    "# Print the date range\n",
    "for game_date in date_range:\n",
    "    \n",
    "    # Construct the base URL\n",
    "    base_url = \"https://stats.ncaa.org/contests/livestream_scoreboards\"\n",
    "    \n",
    "    # Create a dictionary of parameters\n",
    "    params = {\n",
    "        \"utf8\": \"âœ“\",\n",
    "        \"sport_code\": sport_code,\n",
    "        \"academic_year\": academic_year,\n",
    "        \"division\": division,\n",
    "        \"game_date\": game_date,\n",
    "    }\n",
    "    \n",
    "    with Session() as s:\n",
    "        r = s.get(base_url, params=params, headers=_HEADERS)\n",
    "    if r.status_code == 403:\n",
    "        print('An error occurred with the GET Request')\n",
    "        print('403 Error: NCAA blocked request')\n",
    "    \n",
    "    #Retrieve all links to game box score webpages\n",
    "    game_links = get_box_score_links(r.text)\n",
    "    num_games = 0    \n",
    "    for game in game_links:\n",
    "        num_games+=1\n",
    "        url = 'https://stats.ncaa.org'+game\n",
    "        print(f\"Getting stats from: {url}\")\n",
    "        \n",
    "        #------------------------GET URLS FOR BATTING,PITCHING,FIELDING\n",
    "        with Session() as s:\n",
    "            r = s.get(url, headers=_HEADERS)\n",
    "        if r.status_code == 403:\n",
    "            print('An error occurred with the GET Request')\n",
    "            print('403 Error: NCAA blocked request')\n",
    "        soup = BeautifulSoup(r.text, features='lxml')\n",
    "        \n",
    "        # Find the table element that contains the player data\n",
    "        tables = soup.find_all(\"table\")\n",
    "        \n",
    "        team_names = get_team_names(tables[0].prettify())\n",
    "        game_info = get_game_info(tables[2].prettify())\n",
    "        stat_type = tables[4].find_all('a')\n",
    "        \n",
    "        \n",
    "        #Store URLs for batting, pitching and fielding box scores\n",
    "        urls = [stat_type[0]['href'], stat_type[1]['href'], stat_type[2]['href']]\n",
    "        \n",
    "        # Get the home and away stats for each stat type\n",
    "        for i, url in enumerate(urls):\n",
    "            away_df, home_df = get_stats(url)  \n",
    "            ##MAKE INTO FUNCTION\n",
    "            away_df['game_id'] =  int(re.search(r'\\d+', game).group())\n",
    "            home_df['game_id'] = int(re.search(r'\\d+', game).group())\n",
    "            away_df['team'] = team_names[\"Away Team\"]\n",
    "            home_df['team'] = team_names[\"Home Team\"]\n",
    "            away_df['date'] = game_date\n",
    "            home_df['date'] = game_date\n",
    "            away_df['location'] = game_info[\"Location\"]\n",
    "            home_df['location'] = game_info[\"Location\"]\n",
    "            away_df['attendance'] = game_info[\"Attendance\"]\n",
    "            home_df['attendance'] = game_info[\"Attendance\"]\n",
    "            \n",
    "            # Append away and home stats to the final dataframe\n",
    "            if i == 0:  # Batting stats\n",
    "                final_batting_df = pd.concat([final_batting_df, away_df, home_df])\n",
    "            elif i == 1:  # Pitching stats\n",
    "                final_pitching_df = pd.concat([final_pitching_df, away_df, home_df])\n",
    "            elif i == 2:  # Fielding stats\n",
    "                final_fielding_df = pd.concat([final_fielding_df, away_df, home_df])\n",
    "\n",
    "    print(f\"Finished scraping data from {num_games} games on {game_date}\")\n",
    "    new_row = pd.DataFrame({\"Date\": [game_date], \"num_games\": [num_games]})\n",
    "    final_games_per_day = pd.concat([final_games_per_day, new_row], ignore_index=True)\n",
    "      \n",
    "# End the timer and print the elapsed time\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01662dc2-ca04-49d2-b58a-a18472ce04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM DATA (CASTING TO CORRECT DTYPES etc.)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "final_dfs = [final_batting_df, final_pitching_df, final_fielding_df]\n",
    "\n",
    "batting_int_cols = ['G', 'R', 'AB', 'H', '2B', '3B', 'TB', 'HR', 'RBI', 'BB', 'HBP', 'SF', 'SH', 'K', 'OPP DP', 'CS', 'Picked', 'SB', 'IBB', 'GDP', 'RBI2out','game_id','attendance']\n",
    "pitching_int_cols = ['G', 'App', 'GS', 'CG', 'H', 'R', 'ER', 'BB', 'SO', 'SHO', 'BF', 'P-OAB', '2B-A', '3B-A', 'Bk', 'HR-A', 'WP', 'HB', 'IBB', 'Inh Run', 'Inh Run Score', 'SHA', 'SFA', 'Pitches', 'GO', 'FO', 'W', 'L', 'SV', 'OrdAppeared', 'KL', 'pickoffs','game_id','attendance']\n",
    "fielding_int_cols = ['G','PO','A','TC','E','CI','PB','SBA','CSB','IDP','TP','game_id','attendance']\n",
    "\n",
    "for col in batting_int_cols:   \n",
    "    final_batting_df[col] = np.floor(pd.to_numeric(final_batting_df[col], errors='coerce')).astype('Int64')\n",
    "for col in pitching_int_cols:\n",
    "    final_pitching_df[col] = np.floor(pd.to_numeric(final_pitching_df[col], errors='coerce')).astype('Int64')\n",
    "for col in fielding_int_cols:\n",
    "    final_fielding_df[col] = np.floor(pd.to_numeric(final_fielding_df[col], errors='coerce')).astype('Int64')\n",
    "for df in final_dfs:\n",
    "    df['ingestion_date'] = datetime.now()\n",
    "    df = df.astype({\n",
    "        'Player': str,\n",
    "        'Pos': str,\n",
    "        'team': str,\n",
    "        'location': str,\n",
    "        'date': 'datetime64[ns]',\n",
    "        'ingestion_date': 'datetime64[ns]'\n",
    "    })\n",
    "final_pitching_df['IP'] = np.floor(pd.to_numeric(final_pitching_df['IP'], errors='coerce')).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa85eb74-b711-40a6-bf05-420fedf51fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export individual_batting_stats to a CSV file\n",
    "final_batting_df.to_csv(f\"backfill/all_batting_stats_03_11_to_3_11_raw.csv\", index=False)\n",
    "\n",
    "# Export individual_pitching_stats to a CSV file\n",
    "final_pitching_df.to_csv(f\"backfill/all_pitching_stats_03_11_to_3_11_raw.csv\", index=False)\n",
    "\n",
    "final_fielding_df.to_csv(f\"backfill/all_fielding_stats_03_11_to_3_11_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38524a4b-0593-4742-a284-626447bd9721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
